{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2e74f6b-ee17-4459-baf7-dfc80613a00e",
   "metadata": {},
   "source": [
    "# 3.1 SWAT Data Preprocessing\n",
    "First, We will perform pre processing steps on SWAT dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b5a6737",
   "metadata": {},
   "source": [
    "## Importing important Libraries:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b32e9b0e-ac0f-4b24-834c-94ba671db4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd                    # For data manipulation and preprocessing\n",
    "import seaborn as sns                  # For data visualization\n",
    "import numpy as np                     # For numerical operations\n",
    "import matplotlib.pyplot as plt       # For plotting graphs\n",
    "from sklearn.model_selection import train_test_split  # For splitting the dataset into training and testing sets\n",
    "from sklearn.feature_selection import SelectKBest, f_classif  # For feature selection\n",
    "from sklearn.feature_selection import RFE    # For recursive feature elimination\n",
    "from sklearn.ensemble import RandomForestClassifier  # For building a random forest classifier model\n",
    "from sklearn.linear_model import LogisticRegression  # For building a logistic regression classifier model\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix  # For evaluating model performance\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_theme()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e297536d",
   "metadata": {},
   "source": [
    "### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9a42c6f-49c6-4ed4-bda2-1f6a08ee8ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "swat_data = pd.read_csv('SWaT_Dataset_Normal_v1_modified.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4283c5f6",
   "metadata": {},
   "source": [
    "### Describing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c7b6864-f654-498a-9b61-a33a036f37a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "swat training data:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 495000 entries, 0 to 494999\n",
      "Data columns (total 53 columns):\n",
      " #   Column         Non-Null Count   Dtype  \n",
      "---  ------         --------------   -----  \n",
      " 0    Timestamp     495000 non-null  object \n",
      " 1   FIT101         495000 non-null  float64\n",
      " 2   LIT101         495000 non-null  float64\n",
      " 3   MV101          495000 non-null  int64  \n",
      " 4   P101           495000 non-null  int64  \n",
      " 5   P102           495000 non-null  int64  \n",
      " 6   AIT201         495000 non-null  float64\n",
      " 7   AIT202         495000 non-null  float64\n",
      " 8   AIT203         495000 non-null  float64\n",
      " 9   FIT201         495000 non-null  float64\n",
      " 10  MV201          495000 non-null  int64  \n",
      " 11  P201           495000 non-null  int64  \n",
      " 12  P202           495000 non-null  int64  \n",
      " 13  P203           495000 non-null  int64  \n",
      " 14  P204           495000 non-null  int64  \n",
      " 15  P205           495000 non-null  int64  \n",
      " 16  P206           495000 non-null  int64  \n",
      " 17  DPIT301        495000 non-null  float64\n",
      " 18  FIT301         495000 non-null  float64\n",
      " 19  LIT301         495000 non-null  float64\n",
      " 20  MV301          495000 non-null  int64  \n",
      " 21  MV302          495000 non-null  int64  \n",
      " 22  MV303          495000 non-null  int64  \n",
      " 23  MV304          495000 non-null  int64  \n",
      " 24  P301           495000 non-null  int64  \n",
      " 25  P302           495000 non-null  int64  \n",
      " 26  AIT401         495000 non-null  float64\n",
      " 27  AIT402         495000 non-null  float64\n",
      " 28  FIT401         495000 non-null  float64\n",
      " 29  LIT401         495000 non-null  float64\n",
      " 30  P401           495000 non-null  int64  \n",
      " 31  P402           495000 non-null  int64  \n",
      " 32  P403           495000 non-null  int64  \n",
      " 33  P404           495000 non-null  int64  \n",
      " 34  UV401          495000 non-null  int64  \n",
      " 35  AIT501         495000 non-null  float64\n",
      " 36  AIT502         495000 non-null  float64\n",
      " 37  AIT503         495000 non-null  float64\n",
      " 38  AIT504         495000 non-null  float64\n",
      " 39  FIT501         495000 non-null  float64\n",
      " 40  FIT502         495000 non-null  float64\n",
      " 41  FIT503         495000 non-null  float64\n",
      " 42  FIT504         495000 non-null  float64\n",
      " 43  P501           495000 non-null  int64  \n",
      " 44  P502           495000 non-null  int64  \n",
      " 45  PIT501         495000 non-null  float64\n",
      " 46  PIT502         495000 non-null  float64\n",
      " 47  PIT503         495000 non-null  float64\n",
      " 48  FIT601         495000 non-null  float64\n",
      " 49  P601           495000 non-null  int64  \n",
      " 50  P602           495000 non-null  int64  \n",
      " 51  P603           495000 non-null  int64  \n",
      " 52  Normal/Attack  495000 non-null  object \n",
      "dtypes: float64(25), int64(26), object(2)\n",
      "memory usage: 200.2+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>...</th>\n",
       "      <th>FIT504</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.850517</td>\n",
       "      <td>587.532773</td>\n",
       "      <td>1.720564</td>\n",
       "      <td>1.749149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.783544</td>\n",
       "      <td>8.388162</td>\n",
       "      <td>348.379334</td>\n",
       "      <td>1.834095</td>\n",
       "      <td>1.746497</td>\n",
       "      <td>...</td>\n",
       "      <td>0.307254</td>\n",
       "      <td>1.996893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.780601</td>\n",
       "      <td>1.187011</td>\n",
       "      <td>190.928428</td>\n",
       "      <td>0.014427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.007943</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.132519</td>\n",
       "      <td>121.666482</td>\n",
       "      <td>0.457612</td>\n",
       "      <td>0.433503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.787117</td>\n",
       "      <td>0.090233</td>\n",
       "      <td>49.450010</td>\n",
       "      <td>1.059288</td>\n",
       "      <td>0.443279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.017413</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.600787</td>\n",
       "      <td>0.204781</td>\n",
       "      <td>10.614230</td>\n",
       "      <td>0.148934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088771</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.623700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.666200</td>\n",
       "      <td>8.258652</td>\n",
       "      <td>312.278900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.891951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.108177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>508.441000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.734400</td>\n",
       "      <td>8.349654</td>\n",
       "      <td>327.352000</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.306633</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.057252</td>\n",
       "      <td>189.022000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.491432</td>\n",
       "      <td>525.633700</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.284500</td>\n",
       "      <td>8.366636</td>\n",
       "      <td>330.966400</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.308362</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>253.044100</td>\n",
       "      <td>1.121328</td>\n",
       "      <td>191.986000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.592000</td>\n",
       "      <td>676.717500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.982800</td>\n",
       "      <td>8.407652</td>\n",
       "      <td>335.349900</td>\n",
       "      <td>2.451799</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.310284</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.046800</td>\n",
       "      <td>1.217441</td>\n",
       "      <td>193.860500</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.745092</td>\n",
       "      <td>817.556500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>272.526300</td>\n",
       "      <td>8.988273</td>\n",
       "      <td>567.469900</td>\n",
       "      <td>2.487938</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.317010</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.643700</td>\n",
       "      <td>3.668343</td>\n",
       "      <td>200.637600</td>\n",
       "      <td>1.746131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 51 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              FIT101         LIT101          MV101           P101      P102  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.000000  495000.0   \n",
       "mean        1.850517     587.532773       1.720564       1.749149       1.0   \n",
       "std         1.132519     121.666482       0.457612       0.433503       0.0   \n",
       "min         0.000000     120.623700       0.000000       1.000000       1.0   \n",
       "25%         0.000000     508.441000       1.000000       1.000000       1.0   \n",
       "50%         2.491432     525.633700       2.000000       2.000000       1.0   \n",
       "75%         2.592000     676.717500       2.000000       2.000000       1.0   \n",
       "max         2.745092     817.556500       2.000000       2.000000       1.0   \n",
       "\n",
       "              AIT201         AIT202         AIT203         FIT201  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.000000   \n",
       "mean      263.783544       8.388162     348.379334       1.834095   \n",
       "std         4.787117       0.090233      49.450010       1.059288   \n",
       "min       251.666200       8.258652     312.278900       0.000000   \n",
       "25%       260.734400       8.349654     327.352000       0.622016   \n",
       "50%       265.284500       8.366636     330.966400       2.443085   \n",
       "75%       266.982800       8.407652     335.349900       2.451799   \n",
       "max       272.526300       8.988273     567.469900       2.487938   \n",
       "\n",
       "               MV201  ...         FIT504           P501      P502  \\\n",
       "count  495000.000000  ...  495000.000000  495000.000000  495000.0   \n",
       "mean        1.746497  ...       0.307254       1.996893       1.0   \n",
       "std         0.443279  ...       0.017413       0.055654       0.0   \n",
       "min         0.000000  ...       0.000000       1.000000       1.0   \n",
       "25%         2.000000  ...       0.306633       2.000000       1.0   \n",
       "50%         2.000000  ...       0.308362       2.000000       1.0   \n",
       "75%         2.000000  ...       0.310284       2.000000       1.0   \n",
       "max         2.000000  ...       0.317010       2.000000       1.0   \n",
       "\n",
       "              PIT501         PIT502         PIT503         FIT601      P601  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.000000  495000.0   \n",
       "mean      251.780601       1.187011     190.928428       0.014427       1.0   \n",
       "std        13.600787       0.204781      10.614230       0.148934       0.0   \n",
       "min         8.891951       0.000000       3.108177       0.000000       1.0   \n",
       "25%       250.000000       1.057252     189.022000       0.000000       1.0   \n",
       "50%       253.044100       1.121328     191.986000       0.000064       1.0   \n",
       "75%       255.046800       1.217441     193.860500       0.000064       1.0   \n",
       "max       264.643700       3.668343     200.637600       1.746131       1.0   \n",
       "\n",
       "                P602      P603  \n",
       "count  495000.000000  495000.0  \n",
       "mean        1.007943       1.0  \n",
       "std         0.088771       0.0  \n",
       "min         1.000000       1.0  \n",
       "25%         1.000000       1.0  \n",
       "50%         1.000000       1.0  \n",
       "75%         1.000000       1.0  \n",
       "max         2.000000       1.0  \n",
       "\n",
       "[8 rows x 51 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train data\n",
    "print('swat training data:')\n",
    "swat_data.info()\n",
    "swat_data.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef8378",
   "metadata": {},
   "source": [
    "### Missing values check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3781cd83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing Values in Train Data:\n",
      " Timestamp       0\n",
      "FIT101           0\n",
      "LIT101           0\n",
      "MV101            0\n",
      "P101             0\n",
      "P102             0\n",
      "AIT201           0\n",
      "AIT202           0\n",
      "AIT203           0\n",
      "FIT201           0\n",
      "MV201            0\n",
      "P201             0\n",
      "P202             0\n",
      "P203             0\n",
      "P204             0\n",
      "P205             0\n",
      "P206             0\n",
      "DPIT301          0\n",
      "FIT301           0\n",
      "LIT301           0\n",
      "MV301            0\n",
      "MV302            0\n",
      "MV303            0\n",
      "MV304            0\n",
      "P301             0\n",
      "P302             0\n",
      "AIT401           0\n",
      "AIT402           0\n",
      "FIT401           0\n",
      "LIT401           0\n",
      "P401             0\n",
      "P402             0\n",
      "P403             0\n",
      "P404             0\n",
      "UV401            0\n",
      "AIT501           0\n",
      "AIT502           0\n",
      "AIT503           0\n",
      "AIT504           0\n",
      "FIT501           0\n",
      "FIT502           0\n",
      "FIT503           0\n",
      "FIT504           0\n",
      "P501             0\n",
      "P502             0\n",
      "PIT501           0\n",
      "PIT502           0\n",
      "PIT503           0\n",
      "FIT601           0\n",
      "P601             0\n",
      "P602             0\n",
      "P603             0\n",
      "Normal/Attack    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# SWAT Data\n",
    "missing_values_train = swat_data.isnull().sum()\n",
    "print(\"\\nMissing Values in Train Data:\")\n",
    "print(missing_values_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52bebab8",
   "metadata": {},
   "source": [
    "### Duplicate value check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2933f007",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swat_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82b9a412",
   "metadata": {},
   "source": [
    "### Convert categorical variables:\n",
    "\n",
    "#### One-hot encode the categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2abcff93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Categorical column names\n",
    "categorical_col_names = ['Normal/Attack']\n",
    "\n",
    "# Initialize OneHotEncoder\n",
    "encoder = OneHotEncoder()\n",
    "\n",
    "# swat_data \n",
    "one_hot_encoded_train = encoder.fit_transform(swat_data.loc[:,categorical_col_names])\n",
    "\n",
    "one_hot_df_train = pd.DataFrame(one_hot_encoded_train.toarray(), columns=encoder.get_feature_names_out(categorical_col_names))\n",
    "df_train_ecdoded = pd.concat([swat_data, one_hot_df_train], axis=1)\n",
    "df_train_ecdoded = df_train_ecdoded.drop(columns=categorical_col_names, axis=1)\n",
    "df_train = df_train_ecdoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7d6590d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22/12/2015 4:30:00 PM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.3135</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.9226</td>\n",
       "      <td>8.313446</td>\n",
       "      <td>312.7916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3485</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>22/12/2015 4:30:01 PM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.3920</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.9226</td>\n",
       "      <td>8.313446</td>\n",
       "      <td>312.7916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3485</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>22/12/2015 4:30:02 PM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.4705</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.9226</td>\n",
       "      <td>8.313446</td>\n",
       "      <td>312.7916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3485</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>22/12/2015 4:30:03 PM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.6668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.9226</td>\n",
       "      <td>8.313446</td>\n",
       "      <td>312.7916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3485</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22/12/2015 4:30:04 PM</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>124.5098</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>251.9226</td>\n",
       "      <td>8.313446</td>\n",
       "      <td>312.7916</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>9.100231</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.3485</td>\n",
       "      <td>0.000256</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494995</th>\n",
       "      <td>28/12/2015 9:59:55 AM</td>\n",
       "      <td>2.460366</td>\n",
       "      <td>523.0430</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.5055</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.817100</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.8552</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494996</th>\n",
       "      <td>28/12/2015 9:59:56 AM</td>\n",
       "      <td>2.448836</td>\n",
       "      <td>522.9645</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.5055</td>\n",
       "      <td>2.442316</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.817100</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494997</th>\n",
       "      <td>28/12/2015 9:59:57 AM</td>\n",
       "      <td>2.434744</td>\n",
       "      <td>522.8860</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.444879</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.817100</td>\n",
       "      <td>1.778105</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494998</th>\n",
       "      <td>28/12/2015 9:59:58 AM</td>\n",
       "      <td>2.428338</td>\n",
       "      <td>522.9252</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.817100</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5027</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494999</th>\n",
       "      <td>28/12/2015 9:59:59 AM</td>\n",
       "      <td>2.427057</td>\n",
       "      <td>522.8467</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>262.0161</td>\n",
       "      <td>8.396437</td>\n",
       "      <td>328.6337</td>\n",
       "      <td>2.445391</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>250.865200</td>\n",
       "      <td>1.649953</td>\n",
       "      <td>189.5988</td>\n",
       "      <td>0.000128</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495000 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Timestamp    FIT101    LIT101  MV101  P101  P102  \\\n",
       "0        22/12/2015 4:30:00 PM  0.000000  124.3135      1     1     1   \n",
       "1        22/12/2015 4:30:01 PM  0.000000  124.3920      1     1     1   \n",
       "2        22/12/2015 4:30:02 PM  0.000000  124.4705      1     1     1   \n",
       "3        22/12/2015 4:30:03 PM  0.000000  124.6668      1     1     1   \n",
       "4        22/12/2015 4:30:04 PM  0.000000  124.5098      1     1     1   \n",
       "...                        ...       ...       ...    ...   ...   ...   \n",
       "494995   28/12/2015 9:59:55 AM  2.460366  523.0430      2     2     1   \n",
       "494996   28/12/2015 9:59:56 AM  2.448836  522.9645      2     2     1   \n",
       "494997   28/12/2015 9:59:57 AM  2.434744  522.8860      2     2     1   \n",
       "494998   28/12/2015 9:59:58 AM  2.428338  522.9252      2     2     1   \n",
       "494999   28/12/2015 9:59:59 AM  2.427057  522.8467      2     2     1   \n",
       "\n",
       "          AIT201    AIT202    AIT203    FIT201  ...  P501  P502      PIT501  \\\n",
       "0       251.9226  8.313446  312.7916  0.000000  ...     1     1    9.100231   \n",
       "1       251.9226  8.313446  312.7916  0.000000  ...     1     1    9.100231   \n",
       "2       251.9226  8.313446  312.7916  0.000000  ...     1     1    9.100231   \n",
       "3       251.9226  8.313446  312.7916  0.000000  ...     1     1    9.100231   \n",
       "4       251.9226  8.313446  312.7916  0.000000  ...     1     1    9.100231   \n",
       "...          ...       ...       ...       ...  ...   ...   ...         ...   \n",
       "494995  262.0161  8.396437  328.5055  2.442316  ...     2     1  250.817100   \n",
       "494996  262.0161  8.396437  328.5055  2.442316  ...     2     1  250.817100   \n",
       "494997  262.0161  8.396437  328.6337  2.444879  ...     2     1  250.817100   \n",
       "494998  262.0161  8.396437  328.6337  2.445391  ...     2     1  250.817100   \n",
       "494999  262.0161  8.396437  328.6337  2.445391  ...     2     1  250.865200   \n",
       "\n",
       "          PIT502    PIT503    FIT601  P601  P602  P603  Normal/Attack_Normal  \n",
       "0       0.000000    3.3485  0.000256     1     1     1                   1.0  \n",
       "1       0.000000    3.3485  0.000256     1     1     1                   1.0  \n",
       "2       0.000000    3.3485  0.000256     1     1     1                   1.0  \n",
       "3       0.000000    3.3485  0.000256     1     1     1                   1.0  \n",
       "4       0.000000    3.3485  0.000256     1     1     1                   1.0  \n",
       "...          ...       ...       ...   ...   ...   ...                   ...  \n",
       "494995  1.778105  189.8552  0.000128     1     1     1                   1.0  \n",
       "494996  1.778105  189.5027  0.000128     1     1     1                   1.0  \n",
       "494997  1.778105  189.5027  0.000128     1     1     1                   1.0  \n",
       "494998  1.649953  189.5027  0.000128     1     1     1                   1.0  \n",
       "494999  1.649953  189.5988  0.000128     1     1     1                   1.0  \n",
       "\n",
       "[495000 rows x 53 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f95bd7",
   "metadata": {},
   "source": [
    "### Separate features and target variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bad345f",
   "metadata": {},
   "source": [
    "#### -> Dropping Timestamp , and setting Attacktype as Target variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "107a1a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove leading whitespace from column names\n",
    "df_train.columns = df_train.columns.str.strip()\n",
    "\n",
    "# Drop the 'Timestamp' column\n",
    "X_train_data = df_train.drop(columns=['Timestamp'])\n",
    "y_train_data = df_train['Normal/Attack_Normal']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "83e3016b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 495000 entries, 0 to 494999\n",
      "Data columns (total 52 columns):\n",
      " #   Column                Non-Null Count   Dtype  \n",
      "---  ------                --------------   -----  \n",
      " 0   FIT101                495000 non-null  float64\n",
      " 1   LIT101                495000 non-null  float64\n",
      " 2   MV101                 495000 non-null  int64  \n",
      " 3   P101                  495000 non-null  int64  \n",
      " 4   P102                  495000 non-null  int64  \n",
      " 5   AIT201                495000 non-null  float64\n",
      " 6   AIT202                495000 non-null  float64\n",
      " 7   AIT203                495000 non-null  float64\n",
      " 8   FIT201                495000 non-null  float64\n",
      " 9   MV201                 495000 non-null  int64  \n",
      " 10  P201                  495000 non-null  int64  \n",
      " 11  P202                  495000 non-null  int64  \n",
      " 12  P203                  495000 non-null  int64  \n",
      " 13  P204                  495000 non-null  int64  \n",
      " 14  P205                  495000 non-null  int64  \n",
      " 15  P206                  495000 non-null  int64  \n",
      " 16  DPIT301               495000 non-null  float64\n",
      " 17  FIT301                495000 non-null  float64\n",
      " 18  LIT301                495000 non-null  float64\n",
      " 19  MV301                 495000 non-null  int64  \n",
      " 20  MV302                 495000 non-null  int64  \n",
      " 21  MV303                 495000 non-null  int64  \n",
      " 22  MV304                 495000 non-null  int64  \n",
      " 23  P301                  495000 non-null  int64  \n",
      " 24  P302                  495000 non-null  int64  \n",
      " 25  AIT401                495000 non-null  float64\n",
      " 26  AIT402                495000 non-null  float64\n",
      " 27  FIT401                495000 non-null  float64\n",
      " 28  LIT401                495000 non-null  float64\n",
      " 29  P401                  495000 non-null  int64  \n",
      " 30  P402                  495000 non-null  int64  \n",
      " 31  P403                  495000 non-null  int64  \n",
      " 32  P404                  495000 non-null  int64  \n",
      " 33  UV401                 495000 non-null  int64  \n",
      " 34  AIT501                495000 non-null  float64\n",
      " 35  AIT502                495000 non-null  float64\n",
      " 36  AIT503                495000 non-null  float64\n",
      " 37  AIT504                495000 non-null  float64\n",
      " 38  FIT501                495000 non-null  float64\n",
      " 39  FIT502                495000 non-null  float64\n",
      " 40  FIT503                495000 non-null  float64\n",
      " 41  FIT504                495000 non-null  float64\n",
      " 42  P501                  495000 non-null  int64  \n",
      " 43  P502                  495000 non-null  int64  \n",
      " 44  PIT501                495000 non-null  float64\n",
      " 45  PIT502                495000 non-null  float64\n",
      " 46  PIT503                495000 non-null  float64\n",
      " 47  FIT601                495000 non-null  float64\n",
      " 48  P601                  495000 non-null  int64  \n",
      " 49  P602                  495000 non-null  int64  \n",
      " 50  P603                  495000 non-null  int64  \n",
      " 51  Normal/Attack_Normal  495000 non-null  float64\n",
      "dtypes: float64(26), int64(26)\n",
      "memory usage: 196.4 MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>FIT101</th>\n",
       "      <th>LIT101</th>\n",
       "      <th>MV101</th>\n",
       "      <th>P101</th>\n",
       "      <th>P102</th>\n",
       "      <th>AIT201</th>\n",
       "      <th>AIT202</th>\n",
       "      <th>AIT203</th>\n",
       "      <th>FIT201</th>\n",
       "      <th>MV201</th>\n",
       "      <th>...</th>\n",
       "      <th>P501</th>\n",
       "      <th>P502</th>\n",
       "      <th>PIT501</th>\n",
       "      <th>PIT502</th>\n",
       "      <th>PIT503</th>\n",
       "      <th>FIT601</th>\n",
       "      <th>P601</th>\n",
       "      <th>P602</th>\n",
       "      <th>P603</th>\n",
       "      <th>Normal/Attack_Normal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.000000</td>\n",
       "      <td>495000.0</td>\n",
       "      <td>495000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.850517</td>\n",
       "      <td>587.532773</td>\n",
       "      <td>1.720564</td>\n",
       "      <td>1.749149</td>\n",
       "      <td>1.0</td>\n",
       "      <td>263.783544</td>\n",
       "      <td>8.388162</td>\n",
       "      <td>348.379334</td>\n",
       "      <td>1.834095</td>\n",
       "      <td>1.746497</td>\n",
       "      <td>...</td>\n",
       "      <td>1.996893</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.780601</td>\n",
       "      <td>1.187011</td>\n",
       "      <td>190.928428</td>\n",
       "      <td>0.014427</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.007943</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.132519</td>\n",
       "      <td>121.666482</td>\n",
       "      <td>0.457612</td>\n",
       "      <td>0.433503</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.787117</td>\n",
       "      <td>0.090233</td>\n",
       "      <td>49.450010</td>\n",
       "      <td>1.059288</td>\n",
       "      <td>0.443279</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.600787</td>\n",
       "      <td>0.204781</td>\n",
       "      <td>10.614230</td>\n",
       "      <td>0.148934</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.088771</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.623700</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>251.666200</td>\n",
       "      <td>8.258652</td>\n",
       "      <td>312.278900</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.891951</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.108177</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>508.441000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>260.734400</td>\n",
       "      <td>8.349654</td>\n",
       "      <td>327.352000</td>\n",
       "      <td>0.622016</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>1.057252</td>\n",
       "      <td>189.022000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.491432</td>\n",
       "      <td>525.633700</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>265.284500</td>\n",
       "      <td>8.366636</td>\n",
       "      <td>330.966400</td>\n",
       "      <td>2.443085</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>253.044100</td>\n",
       "      <td>1.121328</td>\n",
       "      <td>191.986000</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.592000</td>\n",
       "      <td>676.717500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>266.982800</td>\n",
       "      <td>8.407652</td>\n",
       "      <td>335.349900</td>\n",
       "      <td>2.451799</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>255.046800</td>\n",
       "      <td>1.217441</td>\n",
       "      <td>193.860500</td>\n",
       "      <td>0.000064</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.745092</td>\n",
       "      <td>817.556500</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>272.526300</td>\n",
       "      <td>8.988273</td>\n",
       "      <td>567.469900</td>\n",
       "      <td>2.487938</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>264.643700</td>\n",
       "      <td>3.668343</td>\n",
       "      <td>200.637600</td>\n",
       "      <td>1.746131</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              FIT101         LIT101          MV101           P101      P102  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.000000  495000.0   \n",
       "mean        1.850517     587.532773       1.720564       1.749149       1.0   \n",
       "std         1.132519     121.666482       0.457612       0.433503       0.0   \n",
       "min         0.000000     120.623700       0.000000       1.000000       1.0   \n",
       "25%         0.000000     508.441000       1.000000       1.000000       1.0   \n",
       "50%         2.491432     525.633700       2.000000       2.000000       1.0   \n",
       "75%         2.592000     676.717500       2.000000       2.000000       1.0   \n",
       "max         2.745092     817.556500       2.000000       2.000000       1.0   \n",
       "\n",
       "              AIT201         AIT202         AIT203         FIT201  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.000000   \n",
       "mean      263.783544       8.388162     348.379334       1.834095   \n",
       "std         4.787117       0.090233      49.450010       1.059288   \n",
       "min       251.666200       8.258652     312.278900       0.000000   \n",
       "25%       260.734400       8.349654     327.352000       0.622016   \n",
       "50%       265.284500       8.366636     330.966400       2.443085   \n",
       "75%       266.982800       8.407652     335.349900       2.451799   \n",
       "max       272.526300       8.988273     567.469900       2.487938   \n",
       "\n",
       "               MV201  ...           P501      P502         PIT501  \\\n",
       "count  495000.000000  ...  495000.000000  495000.0  495000.000000   \n",
       "mean        1.746497  ...       1.996893       1.0     251.780601   \n",
       "std         0.443279  ...       0.055654       0.0      13.600787   \n",
       "min         0.000000  ...       1.000000       1.0       8.891951   \n",
       "25%         2.000000  ...       2.000000       1.0     250.000000   \n",
       "50%         2.000000  ...       2.000000       1.0     253.044100   \n",
       "75%         2.000000  ...       2.000000       1.0     255.046800   \n",
       "max         2.000000  ...       2.000000       1.0     264.643700   \n",
       "\n",
       "              PIT502         PIT503         FIT601      P601           P602  \\\n",
       "count  495000.000000  495000.000000  495000.000000  495000.0  495000.000000   \n",
       "mean        1.187011     190.928428       0.014427       1.0       1.007943   \n",
       "std         0.204781      10.614230       0.148934       0.0       0.088771   \n",
       "min         0.000000       3.108177       0.000000       1.0       1.000000   \n",
       "25%         1.057252     189.022000       0.000000       1.0       1.000000   \n",
       "50%         1.121328     191.986000       0.000064       1.0       1.000000   \n",
       "75%         1.217441     193.860500       0.000064       1.0       1.000000   \n",
       "max         3.668343     200.637600       1.746131       1.0       2.000000   \n",
       "\n",
       "           P603  Normal/Attack_Normal  \n",
       "count  495000.0              495000.0  \n",
       "mean        1.0                   1.0  \n",
       "std         0.0                   0.0  \n",
       "min         1.0                   1.0  \n",
       "25%         1.0                   1.0  \n",
       "50%         1.0                   1.0  \n",
       "75%         1.0                   1.0  \n",
       "max         1.0                   1.0  \n",
       "\n",
       "[8 rows x 52 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_data.info()\n",
    "X_train_data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18e5d222",
   "metadata": {},
   "source": [
    "## Imputing missing values with the mean values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21e2d18c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaN Counts after imputation:\n",
      "FIT101                  0\n",
      "LIT101                  0\n",
      "MV101                   0\n",
      "P101                    0\n",
      "P102                    0\n",
      "AIT201                  0\n",
      "AIT202                  0\n",
      "AIT203                  0\n",
      "FIT201                  0\n",
      "MV201                   0\n",
      "P201                    0\n",
      "P202                    0\n",
      "P203                    0\n",
      "P204                    0\n",
      "P205                    0\n",
      "P206                    0\n",
      "DPIT301                 0\n",
      "FIT301                  0\n",
      "LIT301                  0\n",
      "MV301                   0\n",
      "MV302                   0\n",
      "MV303                   0\n",
      "MV304                   0\n",
      "P301                    0\n",
      "P302                    0\n",
      "AIT401                  0\n",
      "AIT402                  0\n",
      "FIT401                  0\n",
      "LIT401                  0\n",
      "P401                    0\n",
      "P402                    0\n",
      "P403                    0\n",
      "P404                    0\n",
      "UV401                   0\n",
      "AIT501                  0\n",
      "AIT502                  0\n",
      "AIT503                  0\n",
      "AIT504                  0\n",
      "FIT501                  0\n",
      "FIT502                  0\n",
      "FIT503                  0\n",
      "FIT504                  0\n",
      "P501                    0\n",
      "P502                    0\n",
      "PIT501                  0\n",
      "PIT502                  0\n",
      "PIT503                  0\n",
      "FIT601                  0\n",
      "P601                    0\n",
      "P602                    0\n",
      "P603                    0\n",
      "Normal/Attack_Normal    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Replace infinity values with NaN\n",
    "X_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute missing values with the mean of each column\n",
    "X_train_data.fillna(X_train_data.mean(), inplace=True)\n",
    "\n",
    "# Check if NaN values have been replaced\n",
    "nan_counts_after_imputation = X_train_data.isnull().sum()\n",
    "print(\"NaN Counts after imputation:\")\n",
    "print(nan_counts_after_imputation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b80d8",
   "metadata": {},
   "source": [
    "# Feature Selection: \n",
    "\n",
    "- I have peformed many techniques below to select features for training the model, like feature importance , Mulitcolinearity Check, RFE, and correaltion analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36243ef3",
   "metadata": {},
   "source": [
    "###  check for multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b14dd66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance Inflation Factor (VIF):\n",
      "                 Feature           VIF\n",
      "51  Normal/Attack_Normal           inf\n",
      "10                  P201           inf\n",
      "31                  P403           inf\n",
      "32                  P404           inf\n",
      "15                  P206           inf\n",
      "29                  P401           inf\n",
      "13                  P204           inf\n",
      "11                  P202           inf\n",
      "43                  P502           inf\n",
      "48                  P601           inf\n",
      "4                   P102           inf\n",
      "50                  P603           inf\n",
      "44                PIT501  1.021839e+04\n",
      "46                PIT503  8.155226e+03\n",
      "38                FIT501  2.069003e+03\n",
      "27                FIT401  1.983333e+03\n",
      "40                FIT503  1.091927e+03\n",
      "33                 UV401  7.427808e+02\n",
      "30                  P402  4.873248e+02\n",
      "41                FIT504  2.459030e+02\n",
      "12                  P203  2.144813e+02\n",
      "8                 FIT201  1.971146e+02\n",
      "42                  P501  1.653114e+02\n",
      "3                   P101  1.436071e+02\n",
      "37                AIT504  1.139841e+02\n",
      "17                FIT301  7.631760e+01\n",
      "16               DPIT301  7.402268e+01\n",
      "9                  MV201  6.065134e+01\n",
      "35                AIT502  5.847158e+01\n",
      "26                AIT402  5.479959e+01\n",
      "24                  P302  4.308238e+01\n",
      "39                FIT502  2.887973e+01\n",
      "0                 FIT101  1.929278e+01\n",
      "20                 MV302  1.868160e+01\n",
      "2                  MV101  1.797851e+01\n",
      "34                AIT501  1.408715e+01\n",
      "14                  P205  1.150807e+01\n",
      "7                 AIT203  1.100683e+01\n",
      "5                 AIT201  8.907255e+00\n",
      "25                AIT401  7.004902e+00\n",
      "36                AIT503  6.521678e+00\n",
      "28                LIT401  5.699897e+00\n",
      "49                  P602  5.661803e+00\n",
      "18                LIT301  5.289020e+00\n",
      "1                 LIT101  4.812454e+00\n",
      "47                FIT601  3.344547e+00\n",
      "19                 MV301  3.044433e+00\n",
      "23                  P301  2.980950e+00\n",
      "21                 MV303  2.310527e+00\n",
      "6                 AIT202  2.156291e+00\n",
      "22                 MV304  2.138501e+00\n",
      "45                PIT502  1.774104e+00\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Suppress RuntimeWarnings\n",
    "np.seterr(divide='ignore', invalid='ignore')\n",
    "\n",
    "# Your existing code for calculating VIF\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Define a function to calculate VIF\n",
    "def calculate_vif(X_train_data):\n",
    "    vif_data = pd.DataFrame()\n",
    "    vif_data[\"Feature\"] = X_train_data.columns\n",
    "    vif_data[\"VIF\"] = [calculate_vif_for_feature(X_train_data, feature) for feature in X_train_data.columns]\n",
    "    return vif_data\n",
    "\n",
    "# Define a function to calculate VIF for a single feature\n",
    "def calculate_vif_for_feature(X, feature_name):\n",
    "    # Exclude the current feature from X_train_data\n",
    "    features_without_current = X_train_data.drop(columns=[feature_name])\n",
    "    \n",
    "    # Fit a linear regression model\n",
    "    model = LinearRegression().fit(features_without_current, X_train_data[feature_name])\n",
    "    \n",
    "    # Predict the current feature\n",
    "    y_pred = model.predict(features_without_current)\n",
    "    \n",
    "    # Calculate R^2 score\n",
    "    r_squared = r2_score(X_train_data[feature_name], y_pred)\n",
    "    \n",
    "    # Calculate VIF\n",
    "    vif = 1 / (1 - r_squared)\n",
    "    \n",
    "    return vif\n",
    "\n",
    "# Calculate VIF for your feature matrix X_train_data\n",
    "vif_result = calculate_vif(X_train_data)\n",
    "\n",
    "# Sort the DataFrame by VIF values in descending order\n",
    "vif_result_sorted = vif_result.sort_values(by='VIF', ascending=False)\n",
    "\n",
    "# Print VIF values in descending order\n",
    "print(\"Variance Inflation Factor (VIF):\")\n",
    "print(vif_result_sorted)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45948f6f",
   "metadata": {},
   "source": [
    "###  Recursive Feature Elimination with Random Forest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29f6fefd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RFE(estimator=RandomForestClassifier(), n_features_to_select=15)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RFE</label><div class=\"sk-toggleable__content\"><pre>RFE(estimator=RandomForestClassifier(), n_features_to_select=15)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "RFE(estimator=RandomForestClassifier(), n_features_to_select=15)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier()\n",
    "rfe = RFE(model, n_features_to_select=15)\n",
    "rfe.fit(X_train_data, y_train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b35861",
   "metadata": {},
   "source": [
    "### Selected features from RFE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e803f4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected features from RFE:\n",
      "Index(['AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502',\n",
      "       'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603',\n",
      "       'Normal/Attack_Normal'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "selected_features_rfe = X_train_data.columns[rfe.support_]\n",
    "print(\"Selected features from RFE:\")\n",
    "print(selected_features_rfe)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283045c2",
   "metadata": {},
   "source": [
    "## So we are considering 'selected_features' as the final list of features from Feature selection process:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4d230ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "selected_features = ['AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502',\n",
    "       'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b06c96",
   "metadata": {},
   "source": [
    "### Correlation analysis on New Features and Existing Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5cf583ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIT503                 NaN\n",
      "PIT502                 NaN\n",
      "PIT501                 NaN\n",
      "P603                   NaN\n",
      "P602                   NaN\n",
      "P601                   NaN\n",
      "P502                   NaN\n",
      "P501                   NaN\n",
      "Normal/Attack_Normal   NaN\n",
      "FIT601                 NaN\n",
      "FIT504                 NaN\n",
      "FIT503                 NaN\n",
      "FIT502                 NaN\n",
      "FIT501                 NaN\n",
      "AIT504                 NaN\n",
      "Name: Normal/Attack_Normal, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Calculate correlation between all features and the target variable\n",
    "correlation_with_target = X_train_data[selected_features + ['Normal/Attack_Normal']].corr()['Normal/Attack_Normal'].sort_index(ascending=False)\n",
    "\n",
    "# Display correlation values\n",
    "print(correlation_with_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b06ae2c",
   "metadata": {},
   "source": [
    "### Final Feature List for training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "67ac5f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           AIT504    FIT501    FIT502    FIT503    FIT504  P501  P502  \\\n",
      "0       123.31450  0.001538  0.001409  0.001664  0.000000     1     1   \n",
      "1       123.31450  0.001538  0.001409  0.001664  0.000000     1     1   \n",
      "2       123.31450  0.001538  0.001409  0.001664  0.000000     1     1   \n",
      "3       123.31450  0.001538  0.001409  0.001664  0.000000     1     1   \n",
      "4       123.31450  0.001538  0.001409  0.001664  0.000000     1     1   \n",
      "...           ...       ...       ...       ...       ...   ...   ...   \n",
      "494995   12.03538  1.726352  1.292430  0.735269  0.308619     2     1   \n",
      "494996   12.03538  1.724942  1.281158  0.735269  0.308619     2     1   \n",
      "494997   12.03538  1.723789  1.272576  0.735269  0.308619     2     1   \n",
      "494998   12.03538  1.723789  1.272576  0.735269  0.308619     2     1   \n",
      "494999   12.03538  1.723789  1.279621  0.735269  0.307786     2     1   \n",
      "\n",
      "            PIT501    PIT502    PIT503    FIT601  P601  P602  P603  \n",
      "0         9.100231  0.000000    3.3485  0.000256     1     1     1  \n",
      "1         9.100231  0.000000    3.3485  0.000256     1     1     1  \n",
      "2         9.100231  0.000000    3.3485  0.000256     1     1     1  \n",
      "3         9.100231  0.000000    3.3485  0.000256     1     1     1  \n",
      "4         9.100231  0.000000    3.3485  0.000256     1     1     1  \n",
      "...            ...       ...       ...       ...   ...   ...   ...  \n",
      "494995  250.817100  1.778105  189.8552  0.000128     1     1     1  \n",
      "494996  250.817100  1.778105  189.5027  0.000128     1     1     1  \n",
      "494997  250.817100  1.778105  189.5027  0.000128     1     1     1  \n",
      "494998  250.817100  1.649953  189.5027  0.000128     1     1     1  \n",
      "494999  250.865200  1.649953  189.5988  0.000128     1     1     1  \n",
      "\n",
      "[495000 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Concatenate dataframes along columns\n",
    "df_final = X_train_data[selected_features]\n",
    "\n",
    "# Display the combined dataframe\n",
    "print(df_final)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6d6edf3",
   "metadata": {},
   "source": [
    "# Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29b56ea",
   "metadata": {},
   "source": [
    "## Using MinMaxScaler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f8064d",
   "metadata": {},
   "source": [
    "### First, I performed individually on Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5095c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Select the columns from the DataFrame\n",
    "X_final = df_final[selected_features]\n",
    "\n",
    "# Initialize MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "# Fit and transform the features\n",
    "X_scaled_train = scaler.fit_transform(X_final)\n",
    "\n",
    "# Use X_scaled_standard for further analysis or modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d2c6a0dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scaled Trained Data: X_scaled_train\n",
      "[[5.27549303e-01 1.45942525e-04 5.64883354e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14383482e-04\n",
      "  0.00000000e+00 1.21664406e-03 1.46783661e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.27549303e-01 1.45942525e-04 5.64883354e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14383482e-04\n",
      "  0.00000000e+00 1.21664406e-03 1.46783661e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.27549303e-01 1.45942525e-04 5.64883354e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14383482e-04\n",
      "  0.00000000e+00 1.21664406e-03 1.46783661e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.27549303e-01 1.45942525e-04 5.64883354e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14383482e-04\n",
      "  0.00000000e+00 1.21664406e-03 1.46783661e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]\n",
      " [5.27549303e-01 1.45942525e-04 5.64883354e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00 0.00000000e+00 8.14383482e-04\n",
      "  0.00000000e+00 1.21664406e-03 1.46783661e-04 0.00000000e+00\n",
      "  0.00000000e+00 0.00000000e+00]]\n"
     ]
    }
   ],
   "source": [
    "print('Scaled Trained Data: X_scaled_train')\n",
    "print(X_scaled_train[:5])  # Print the first 5 rows of the scaled features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4e14c0",
   "metadata": {},
   "source": [
    "### Note: After Scaling the Train and Test data, We can start working on model development, We will use Scale Train Data for training new models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7673ad35",
   "metadata": {},
   "source": [
    "# 3.2 Model Development"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab7c4aa",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31496a4",
   "metadata": {},
   "source": [
    "### Splitting the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8cf2c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "X = X_scaled_train\n",
    "y = df_train['Normal/Attack_Normal']\n",
    "\n",
    "# Split the data into training and testing sets (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Random forest classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d7d64b5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Instantiate the model\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a35db71e",
   "metadata": {},
   "source": [
    "## To predict whether a system has been under attack or not based on your dataset with attack types, you can approach it as a binary classification problem where the target variable is binary: 1 for \"under attack\" and 0 for \"not under attack\" (normal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5a92f992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00     99000\n",
      "\n",
      "    accuracy                           1.00     99000\n",
      "   macro avg       1.00      1.00      1.00     99000\n",
      "weighted avg       1.00      1.00      1.00     99000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Data Preparation\n",
    "# Assume X_train, X_test, y_train, y_test are prepared\n",
    "\n",
    "# Model Training\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Model Evaluation\n",
    "y_pred = model.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Feature Importance\n",
    "feature_importance = model.feature_importances_\n",
    "# Analyze feature importance to understand which features are important for classification\n",
    "\n",
    "# Deployment and Monitoring\n",
    "# Deploy the trained model into production and monitor its performance over time\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7898f8fc",
   "metadata": {},
   "source": [
    "# Saving our trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "924868dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# After training your model\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import joblib\n",
    "\n",
    "# Assume `model` is your trained RandomForestClassifier\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Save the trained model to a file\n",
    "joblib.dump(model, 'random_forest_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "03b1279d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: scikit-learn\n",
      "Version: 1.2.2\n",
      "Summary: A set of python modules for machine learning and data mining\n",
      "Home-page: http://scikit-learn.org\n",
      "Author: \n",
      "Author-email: \n",
      "License: new BSD\n",
      "Location: /opt/anaconda3/envs/XAI/lib/python3.11/site-packages\n",
      "Requires: joblib, numpy, scipy, threadpoolctl\n",
      "Required-by: imbalanced-learn\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c81555a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y3/6_jzyflj4v7g578qn0rp6yt00000gn/T/ipykernel_35405/501301805.py:27: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
      "/var/folders/y3/6_jzyflj4v7g578qn0rp6yt00000gn/T/ipykernel_35405/501301805.py:28: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X_train_data.fillna(X_train_data.mean(), inplace=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       1.00      1.00      1.00     99000\n",
      "\n",
      "    accuracy                           1.00     99000\n",
      "   macro avg       1.00      1.00      1.00     99000\n",
      "weighted avg       1.00      1.00      1.00     99000\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['random_forest_model.pkl']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Short script for this ML model:\n",
    "\n",
    "# import pandas as pd\n",
    "# import numpy as np\n",
    "# import joblib\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "# from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# # Load data\n",
    "# swat_data = pd.read_csv('SWaT_Dataset_Normal_v1_modified.csv')\n",
    "\n",
    "# # One-hot encode the target variable\n",
    "# categorical_col_names = ['Normal/Attack']\n",
    "# encoder = OneHotEncoder()\n",
    "# one_hot_encoded_train = encoder.fit_transform(swat_data.loc[:, categorical_col_names])\n",
    "# one_hot_df_train = pd.DataFrame(one_hot_encoded_train.toarray(), columns=encoder.get_feature_names_out(categorical_col_names))\n",
    "# df_train_encoded = pd.concat([swat_data, one_hot_df_train], axis=1)\n",
    "# df_train_encoded = df_train_encoded.drop(columns=categorical_col_names, axis=1)\n",
    "# df_train = df_train_encoded\n",
    "\n",
    "# # Prepare features and target variable\n",
    "# selected_features = ['AIT504', 'FIT501', 'FIT502', 'FIT503', 'FIT504', 'P501', 'P502', 'PIT501', 'PIT502', 'PIT503', 'FIT601', 'P601', 'P602', 'P603']\n",
    "# X_train_data = df_train[selected_features]\n",
    "# y_train_data = df_train['Normal/Attack_Normal']\n",
    "\n",
    "# # Handle missing values\n",
    "# X_train_data.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "# X_train_data.fillna(X_train_data.mean(), inplace=True)\n",
    "\n",
    "# # Scale the features\n",
    "# scaler = MinMaxScaler()\n",
    "# X_scaled_train = scaler.fit_transform(X_train_data)\n",
    "\n",
    "# # Train/test split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_scaled_train, y_train_data, test_size=0.2, random_state=42)\n",
    "\n",
    "# # Train RandomForest model\n",
    "# rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "# rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate model\n",
    "# y_pred = rf_classifier.predict(X_test)\n",
    "# print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "# # Save the trained model\n",
    "# joblib.dump((rf_classifier, scaler, selected_features), 'random_forest_model.pkl')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
